{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Use Active Learning to Link FEBRL People Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"https://colab.research.google.com/github/rachhouse/intro-to-data-linking/blob/main/tutorial_notebooks/03_Link_FEBRL_Data_with_Active_Learning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this tutorial, we'll use the [dedupe library](https://github.com/dedupeio/dedupe) to experiment with an active learning approach to linking our FEBRL people datasets.\n",
    "\n",
    "Once again, we'll use the same training dataset and evaluation functions as the SimSum classification tutorial; these have been included in a separate `.py` file for re-use and convenience, so we can focus on code unique to this tutorial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Google Colab Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check if we're running locally, or in Google Colab.\n",
    "try:\n",
    "    import google.colab\n",
    "    COLAB = True\n",
    "except ModuleNotFoundError:\n",
    "    COLAB = False\n",
    "    \n",
    "# If we're running in Colab, download the tutorial functions file \n",
    "# to the Colab session local directory, and install required libraries.\n",
    "if COLAB:\n",
    "    import requests\n",
    "    \n",
    "    tutorial_functions_url = \"https://raw.githubusercontent.com/rachhouse/intro-to-data-linking/main/tutorial_notebooks/linking_tutorial_functions.py\"\n",
    "    r = requests.get(tutorial_functions_url)\n",
    "    \n",
    "    with open(\"linking_tutorial_functions.py\", \"w\") as fh:\n",
    "        fh.write(r.text)\n",
    "    \n",
    "    !pip install -q altair dedupe dedupe-variable-name jellyfish recordlinkage "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "import itertools\n",
    "import os\n",
    "import pathlib\n",
    "import re\n",
    "from typing import Any, Dict, Optional\n",
    "\n",
    "import dedupe\n",
    "import pandas as pd\n",
    "\n",
    "import linking_tutorial_functions as tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Working Filepaths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For convenience, we'll define a `pathlib.Path` to reference our current working directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WORKING_DIR = pathlib.Path(os.path.abspath(''))\n",
    "WORKING_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Training Dataset and Ground Truth Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A, df_B, df_ground_truth = tutorial.load_febrl_training_data(COLAB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a quick look at our training dataset to refresh on the columns, formats, and data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_A.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll do minimal data augmentation before feeding our training data to `dedupe`; we just want to format the date of birth data as `mm/dd/yy`, and ensure all columns are in string format and stripped of trailing/leading whitespace. Additionally, `dedupe` requires input data to be in dictionaries, using the record id as the key and the record metadata as the value. So, we'll convert our dataframes to this format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_dob(dob: str) -> Optional[str]:\n",
    "    \"\"\" Transform date of birth format from YYYYMMDD to mm/dd/yy.\n",
    "        If DOB cannot be transformed, return None.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        if re.match(r\"\\d{8}\", dob):\n",
    "            return (datetime.datetime.strptime(dob, \"%Y%m%d\")).strftime(\"%m/%d/%y\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    return None\n",
    "\n",
    "def strip_and_null(x: Any) -> Optional[str]:\n",
    "    \"\"\" Stringify incoming variable, remove trailing/leading whitespace\n",
    "        and return resulting string. Return None if resulting string is empty.\n",
    "    \"\"\"\n",
    "    x = str(x).strip()\n",
    "    \n",
    "    if x == \"\":\n",
    "        return None\n",
    "    else:\n",
    "        return x\n",
    "    \n",
    "def convert_df_to_dict(df: pd.DataFrame) -> Dict[str, Dict]:\n",
    "    \"\"\" Convert pandas DataFrame to dict keyed by record id.\n",
    "        Convert all fields to strings or Nones to satisfy dedupe.\n",
    "        Transform date format of date_of_birth field.\n",
    "    \"\"\"    \n",
    "\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].apply(lambda x: strip_and_null(x))\n",
    "\n",
    "    df[\"date_of_birth\"] = df[\"date_of_birth\"].apply(lambda x: format_dob(x))    \n",
    "\n",
    "    return df.to_dict(\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "records_A = convert_df_to_dict(df_A)\n",
    "records_B = convert_df_to_dict(df_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can examine a small sample of the resulting transformed records:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[records_A[k] for k in list(records_A.keys())[0:2]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we linked our data via SimSum and supervised learning, we defined our blockers and comparators manually with `recordlinkage`. The `dedupe` library takes an active learning approach to blocking and classification and will use our feedback gathered during the labeling session to learn blocking rules and train a classifier. \n",
    "\n",
    "To prepare our `dedupe.RecordLink` object for training, first we'll define the fields that we think `dedupe` should pay attention to when matching records - these definitions will serve as the comparators. The `field` contains the name of the attribute to use for comparison, and the `type` defines the comparison type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fields = [\n",
    "    { \"field\" : \"first_name\", \"type\" : \"Name\" },\n",
    "    { \"field\" : \"surname\", \"type\" : \"Name\" },\n",
    "    { \"field\" : \"address_1\", \"type\" : \"ShortString\" },\n",
    "    { \"field\" : \"address_2\", \"type\" : \"ShortString\" },\n",
    "    { \"field\" : \"suburb\", \"type\" : \"ShortString\" },\n",
    "    { \"field\" : \"postcode\", \"type\" : \"Exact\" },\n",
    "    { \"field\" : \"state\", \"type\" : \"Exact\" },\n",
    "    { \"field\" : \"date_of_birth\", \"type\" : \"DateTime\" },\n",
    "    { \"field\" : \"soc_sec_id\", \"type\" : \"Exact\" },\n",
    "]\n",
    "\n",
    "linker = dedupe.RecordLink(fields)\n",
    "linker.prepare_training(records_A, records_B)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Active Learning Labeling Session!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At this point, we're ready to provide feedback to `dedupe` via an active learning labeling session. For this, `dedupe` supplies a convenience method to iterate through pairs it is uncertain about. As you provide feedback for each pair, dedupe learns blocking rules and recalculates its linking model weights.\n",
    "\n",
    "You can use `y` (yes, match), `n` (no, not match), and `u` (unsure) to provide feedback on candidate links. When you're ready to exit the labeling session, use `f`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dedupe.console_label(linker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now train our linker, based on the labeling session feedback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "linker.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's persist our training data (captured during in the labeling session), as well as the learned model weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ACTIVE_LEARNING_DIR = WORKING_DIR / \"dedupe_active_learning\"\n",
    "ACTIVE_LEARNING_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "SETTINGS_FILE = ACTIVE_LEARNING_DIR / \"dedupe_learned_settings\"\n",
    "TRAINING_FILE = ACTIVE_LEARNING_DIR / \"dedupe_training.json\"\n",
    "\n",
    "with open(TRAINING_FILE, \"w\") as fh:\n",
    "    linker.write_training(fh)\n",
    "    \n",
    "with open(SETTINGS_FILE, \"wb\") as sf:\n",
    "    linker.write_settings(sf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examine Learned Blockers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at the predicates (blockers) that `dedupe` learned during our active learning labeling session. Note that `dedupe` can learn composite predicates/blockers, i.e. individual predicates can be combined with logical operators."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linker.predicates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, let's examine the resulting candidate pairs and look at our blocking efficiency. The `.pairs` method will give us all candidate record pairs that are generated by blocking with the learned blockers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pairs = [x for x in linker.pairs(records_A, records_B)]\n",
    "print(f\"{len(candidate_pairs):,} candidate pairs generated from blocking.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll notice that, in contrast to `recordlinkage`, our post-blocking candidate pairs contain both the record ids as well as the record metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pairs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can assemble our candidate pair ids into an indexed pandas dataframe for easier comparision with our known true links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_candidate_links = pd.DataFrame(\n",
    "    [(x[0][0], x[1][0]) for x in candidate_pairs]\n",
    ").rename(columns={0 : \"person_id_A\", 1 : \"person_id_B\"}).set_index([\"person_id_A\", \"person_id_B\"])\n",
    "\n",
    "df_candidate_links.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's take a look at our learned blocker performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_candidate_pairs = df_A.shape[0]*df_B.shape[0]\n",
    "\n",
    "print(f\"{max_candidate_pairs:,} total possible pairs.\")\n",
    "\n",
    "# Calculate search space reduction.\n",
    "search_space_reduction = round(1 - len(candidate_pairs)/max_candidate_pairs, 6)\n",
    "print(f\"\\n{len(candidate_pairs):,} pairs after full blocking: {search_space_reduction}% search space reduction.\")\n",
    "\n",
    "# Calculate retained true links percentage.\n",
    "total_true_links = df_ground_truth.shape[0]\n",
    "true_links_after_blocking = pd.merge(\n",
    "    df_ground_truth,\n",
    "    df_candidate_links,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"inner\"\n",
    ").shape[0]\n",
    "\n",
    "retained_true_link_percent = round((true_links_after_blocking/total_true_links) * 100, 2)\n",
    "print(f\"{retained_true_link_percent}% true links retained after blocking.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Score Pairs and Examine Learned Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After `dedupe` has trained blockers and a classification model based on our labeling session, we can link the records in our training dataset via the `.join` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "linked_records = linker.join(records_A, records_B, threshold=0.0, constraint=\"one-to-one\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`linker.join` will return the links, along with a model confidence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "linked_records[0:3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll format the `dedupe` linker predictions into a format that we can use with our existing evaluation functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = pd.DataFrame(\n",
    "    [ {\"person_id_A\" : x[0][0], \"person_id_B\" : x[0][1], \"model_score\" : x[1]} for x in linked_records]\n",
    ")\n",
    "\n",
    "df_predictions = df_predictions.set_index([\"person_id_A\", \"person_id_B\"])\n",
    "\n",
    "df_predictions = pd.merge(\n",
    "    df_predictions,\n",
    "    df_ground_truth,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "df_predictions[\"ground_truth\"].fillna(False, inplace=True)\n",
    "df_predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Choosing a Linking Model Score Threshold"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `dedupe` `.join` method that we used to score our training data directly incorporates the learned blockers. Thus, note that the scored pairs appearing on the distribution represent blocked pairs, and that our blockers *significantly* reduced the candidate pair search space."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Score Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions[\"ground_truth\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial.plot_model_score_distribution(df_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Precision and Recall vs. Model Score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = tutorial.evaluate_linking(\n",
    "    df=df_predictions\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial.plot_precision_recall_vs_threshold(df_eval)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iterating with Active Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When using active learning, we iterate on our linking solution, and incorporate progressively more labeled training data. Perhaps we're not satisfied with the current performance of the blockers or classifier, and we'd like to create more labeled examples for dedupe to train on.\n",
    "\n",
    "Recall that earlier, we saved off our existing training data from the first labeling session. We can load this persisted data into a `dedupe` linker, and kick off another labeling session. Perhaps, after investigating the data during our first cycle, we don't think that dedupe should include `address_1` and `address2` in its comparators."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tweak the Linker and Use Existing Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "fields = [\n",
    "    { \"field\" : \"first_name\", \"type\" : \"Name\" },\n",
    "    { \"field\" : \"surname\", \"type\" : \"Name\" },\n",
    "    { \"field\" : \"suburb\", \"type\" : \"ShortString\" },\n",
    "    { \"field\" : \"postcode\", \"type\" : \"Exact\" },\n",
    "    { \"field\" : \"state\", \"type\" : \"Exact\" },\n",
    "    { \"field\" : \"date_of_birth\", \"type\" : \"DateTime\" },\n",
    "    { \"field\" : \"soc_sec_id\", \"type\" : \"Exact\" },\n",
    "]\n",
    "\n",
    "linker2 = dedupe.RecordLink(fields)\n",
    "\n",
    "with open(TRAINING_FILE, \"r\") as fh:\n",
    "    linker2.prepare_training(records_A, records_B, training_file=fh)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can kick off a second active learning/labeling session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dedupe.console_label(linker2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retrain the Linker and Examine Blocking Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's retrain, and examine blocker performance. Ideally, we see an improved true link retention following our second labeling session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "linker2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "candidate_pairs = [x for x in linker2.pairs(records_A, records_B)]\n",
    "print(f\"{len(candidate_pairs):,} candidate pairs generated from blocking.\")\n",
    "\n",
    "df_candidate_links = pd.DataFrame(\n",
    "    [(x[0][0], x[1][0]) for x in candidate_pairs]\n",
    ").rename(columns={0 : \"person_id_A\", 1 : \"person_id_B\"}).set_index([\"person_id_A\", \"person_id_B\"])\n",
    "\n",
    "max_candidate_pairs = df_A.shape[0]*df_B.shape[0]\n",
    "\n",
    "print(f\"{max_candidate_pairs:,} total possible pairs.\")\n",
    "\n",
    "# Calculate search space reduction.\n",
    "search_space_reduction = round(1 - len(candidate_pairs)/max_candidate_pairs, 6)\n",
    "print(f\"\\n{len(candidate_pairs):,} pairs after full blocking: {search_space_reduction}% search space reduction.\")\n",
    "\n",
    "# Calculate retained true links percentage.\n",
    "total_true_links = df_ground_truth.shape[0]\n",
    "true_links_after_blocking = pd.merge(\n",
    "    df_ground_truth,\n",
    "    df_candidate_links,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"inner\"\n",
    ").shape[0]\n",
    "\n",
    "retained_true_link_percent = round((true_links_after_blocking/total_true_links) * 100, 2)\n",
    "print(f\"{retained_true_link_percent}% true links retained after blocking.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Classification Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "linked_records = linker2.join(records_A, records_B, threshold=0.0, constraint=\"one-to-one\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions = pd.DataFrame(\n",
    "    [ {\"person_id_A\" : x[0][0], \"person_id_B\" : x[0][1], \"model_score\" : x[1]} for x in linked_records]\n",
    ")\n",
    "\n",
    "df_predictions = df_predictions.set_index([\"person_id_A\", \"person_id_B\"])\n",
    "\n",
    "df_predictions = pd.merge(\n",
    "    df_predictions,\n",
    "    df_ground_truth,\n",
    "    left_index=True,\n",
    "    right_index=True,\n",
    "    how=\"left\",\n",
    ")\n",
    "\n",
    "df_predictions[\"ground_truth\"].fillna(False, inplace=True)\n",
    "df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_predictions[\"ground_truth\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tutorial.plot_model_score_distribution(df_predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_eval = tutorial.evaluate_linking(\n",
    "    df=df_predictions\n",
    ")\n",
    "\n",
    "tutorial.plot_precision_recall_vs_threshold(df_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "linking",
   "language": "python",
   "name": "linking"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
