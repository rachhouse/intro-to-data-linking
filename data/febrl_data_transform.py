""" Contains functions to parse original FEBRL data (generated by the dsgen code)
    into pandas DataFrames for use in data linking tutorials.
"""

import pathlib
import re
import uuid
from typing import Optional, Tuple

import pandas as pd

DATASET_COLUMNS = [
    "person_id",
    "first_name",
    "surname",
    "street_number",
    "address_1",
    "address_2",
    "suburb",
    "postcode",
    "state",
    "date_of_birth",
    "age",
    "phone_number",
    "soc_sec_id",
]

ORIGINAL_RECORD_PATTERN = r"rec-(\d+)-org"
DUPE_RECORD_PATTERN = r"rec-(\d+)-dup-(\d+)"


def _parse_rec_id(rec_id: str) -> Tuple[int, bool, Optional[int]]:
    """Dissect the rec_id field of a FEBRL data row.

    Args:
        rec_id: str record id field from original FEBRL data row

    Returns:
        record id (int)
        dataset (A or B)
        Optional duplicate number, if exists, otherwise None
    """

    if m := re.match(ORIGINAL_RECORD_PATTERN, rec_id):
        return [int(m.group(1)), "A", None]
    elif m := re.match(DUPE_RECORD_PATTERN, rec_id):
        return [int(m.group(1)), "B", m.group(2)]
    else:
        raise Exception(f"Unable to parse rec_id: {rec_id}")


def _convert_febrl_dataset(
    febrl_file: pathlib.Path, contains_dupes: bool = True
) -> Tuple[pd.DataFrame, Optional[pd.DataFrame], Optional[pd.DataFrame]]:
    """Convert a csv file of FEBRL data into pandas DataFrame(s) for data linking.

    Args:
        febrl_file: pathlib.Path to csv file containing FEBRL data
        contains_dupes: bool indicating whether the file contains duplicates

    Returns:
        * if contains_dupes: pd.DataFrame with Dataset A (originals),
            pd.DataFrame with Dataset B (duplicates), pd.DataFrame with known
            true links
        * if not contains_dupes: single pd.Dataframe with formatted records
    """

    df_febrl = pd.read_csv(febrl_file)
    df_febrl.columns = [x.strip() for x in df_febrl.columns]
    df_febrl.drop("blocking_number", axis=1, inplace=True)
    df_febrl.rename(columns={"given_name": "first_name"}, inplace=True)

    df_febrl["first_name"] = df_febrl["first_name"].apply(lambda x: x.strip())
    df_febrl["surname"] = df_febrl["surname"].apply(lambda x: x.strip())

    # Generate a random uuid for each row.
    df_febrl["person_id"] = df_febrl["rec_id"].apply(lambda x: str(uuid.uuid4()))

    # Parse out duplicate infomation.
    # Originals go into dataset A and dupes go into dataset B.
    df_febrl[["febrl_id", "dataset", "dupe_no"]] = df_febrl.apply(
        lambda x: pd.Series(_parse_rec_id(x["rec_id"])), axis=1
    )

    if contains_dupes:

        unique_febrl_ids = sorted(list(df_febrl["febrl_id"].unique()))

        # Map febrl id to the new person uuids to construct the true link/
        # ground truth labels.
        training_labels = []
        for febrl_id in unique_febrl_ids:
            person_id_A = df_febrl[
                (df_febrl["febrl_id"] == febrl_id) & (df_febrl["dataset"] == "A")
            ].iloc[0]["person_id"]
            person_id_B = df_febrl[
                (df_febrl["febrl_id"] == febrl_id) & (df_febrl["dataset"] == "B")
            ].iloc[0]["person_id"]

            training_labels.append(
                {
                    "person_id_A": person_id_A,
                    "person_id_B": person_id_B,
                    "ground_truth": 1,
                }
            )

        df_labels = pd.DataFrame(training_labels)

    df_febrl = df_febrl.drop(["rec_id", "febrl_id", "dupe_no"], axis=1)
    df_febrl = df_febrl[["dataset"] + DATASET_COLUMNS]

    # Assemble dataset A (left).
    df_A = df_febrl[df_febrl["dataset"] == "A"].copy()
    df_A.reset_index(inplace=True, drop=True)
    df_A = df_A[DATASET_COLUMNS]
    df_A.rename(columns={"person_id": "person_id_A"}, inplace=True)

    if not contains_dupes:
        return df_A, None, None

    # Assemble dataset B (right).
    df_B = df_febrl[df_febrl["dataset"] == "B"].copy()
    df_B.reset_index(inplace=True, drop=True)
    df_B = df_B[DATASET_COLUMNS]
    df_B.rename(columns={"person_id": "person_id_B"}, inplace=True)

    return df_A, df_B, df_labels


def transform_febrl_dataset_without_dupes(febrl_file: pathlib.Path) -> pd.DataFrame:
    """Transform and clean FEBRL dataset into pd.DataFrame.

    Args:
        febrl_file: pathlib.Path to FEBRL data in CSV format

    Returns:
        pd.Dataframe with formatted people records
    """
    df_febrl, _, _ = _convert_febrl_dataset(febrl_file, contains_dupes=False)
    return df_febrl


def transform_febrl_dataset_with_dupes(
    febrl_file: pathlib.Path,
) -> Tuple[pd.DataFrame, pd.DataFrame, pd.DataFrame]:
    """Transform and clean FEBRL dataset into pd.DataFrame.

    Args:
        febrl_file: pathlib.Path to FEBRL data in CSV format

    Returns:
        * pd.DataFrame with Dataset A people records (originals)
        * pd.DataFrame with Dataset B people records (duplicates)
        * pd.DataFrame with known true links
    """
    return _convert_febrl_dataset(febrl_file, contains_dupes=True)
